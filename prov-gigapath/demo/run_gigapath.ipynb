{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prov-GigaPath inference demo\n",
    "\n",
    "The Prov-GigaPath models can be accessed from [HuggingFace Hub](https://huggingface.co/prov-gigapath/prov-gigapath).\n",
    "\n",
    "You need to agree to the terms to access the models. Once you have the necessary access, set your HuggingFace read-only token as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"<HuggingFace Token>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare image tiles\n",
    "\n",
    "To facilitate the demo, you can access and download preprocessed tiles from this link: https://hanoverprod.z21.web.core.windows.net/gigapath/PANDA_sample_tiles.zip\n",
    "\n",
    "The zip file includes a sample slide we processed from the PANDA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 810 image tiles\n"
     ]
    }
   ],
   "source": [
    "slide_dir = \"data/PANDA_sample_tiles/054b6888604d963455bfff551518ece5/\"\n",
    "image_paths = [os.path.join(slide_dir, img) for img in os.listdir(slide_dir) if img.endswith('.png')]\n",
    "\n",
    "print(f\"Found {len(image_paths)} image tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tile and slide encoder model separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timm\n",
    "import gigapath.slide_encoder as slide_encoder\n",
    "\n",
    "\n",
    "# load the tile encoder\n",
    "tile_encoder = timm.create_model(\"hf_hub:prov-gigapath/prov-gigapath\", pretrained=True)\n",
    "# load the slide encoder\n",
    "slide_encoder_model = slide_encoder.create_model(\"hf_hub:prov-gigapath/prov-gigapath\", \"gigapath_slide_enc12l768d\", 1536)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load both the tile and slide encoder model at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naotous/miniconda3/envs/run_gigapath/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile encoder param # 1134953984\n",
      "dilated_ratio:  [1, 2, 4, 8, 16]\n",
      "segment_length:  [1024, 5792, 32768, 185363, 1048576]\n",
      "Number of trainable LongNet parameters:  85148160\n",
      "Global Pooling: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "slide_encoder.pth: 100%|██████████| 345M/345M [00:00<00:00, 366MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Successfully Loaded Pretrained GigaPath model from hf_hub:prov-gigapath/prov-gigapath \u001b[00m\n",
      "Slide encoder param # 86330880\n"
     ]
    }
   ],
   "source": [
    "from gigapath.pipeline import load_tile_slide_encoder\n",
    "# load the tile and slide encoder models\n",
    "# Note: Older versions of timm have compatibility issues. \n",
    "# Please ensure that you use a newer version by running the following command: pip install timm>=1.0.3.\n",
    "tile_encoder, slide_encoder_model = load_tile_slide_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inferrence with tile encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([810, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([810, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gigapath.pipeline import run_inference_with_tile_encoder\n",
    "# run inference with the tile encoder\n",
    "tile_encoder_outputs = run_inference_with_tile_encoder(image_paths, tile_encoder)\n",
    "\n",
    "for k in tile_encoder_outputs.keys():\n",
    "    print(f\"tile_encoder_outputs[{k}].shape: {tile_encoder_outputs[k].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference with the slide encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['layer_0_embed', 'layer_1_embed', 'layer_2_embed', 'layer_3_embed', 'layer_4_embed', 'layer_5_embed', 'layer_6_embed', 'layer_7_embed', 'layer_8_embed', 'layer_9_embed', 'layer_10_embed', 'layer_11_embed', 'layer_12_embed', 'last_layer_embed'])\n"
     ]
    }
   ],
   "source": [
    "from gigapath.pipeline import run_inference_with_slide_encoder\n",
    "# run inference with the slide encoder\n",
    "slide_embeds = run_inference_with_slide_encoder(slide_encoder_model=slide_encoder_model, **tile_encoder_outputs)\n",
    "print(slide_embeds.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional notes\n",
    "\n",
    "In this demo, we provided a walkthrough of running the pretrained Prov-GigaPath model. For instructions on fine-tuning the model, please refer to the following link: [Fine-Tuning Instructions](https://github.com/prov-gigapath/prov-gigapath?tab=readme-ov-file#fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gigapath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
